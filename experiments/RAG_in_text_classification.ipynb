{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the embedding model first\n",
    "from torch import cuda\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "# Confirm GPU usage\n",
    "if cuda.is_available():\n",
    "    device = f'cuda:{cuda.current_device()}'\n",
    "    print(\"Using GPU:\", device)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=embed_model_id,\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'device': device, 'batch_size': 32}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Path to the updated JSON file\n",
    "updated_json_file_path = '/root/llama/datasets/classification_task_new_labels.json'  \n",
    "\n",
    "# Read the updated JSON file\n",
    "with open(updated_json_file_path, 'r', encoding='utf-8') as file:\n",
    "    updated_data = json.load(file)\n",
    "\n",
    "# Number of entries to display\n",
    "num_entries_to_display = 5\n",
    "\n",
    "# Print the first few entries to check the labels\n",
    "for entry in updated_data[:num_entries_to_display]:\n",
    "    print(f\"Label: {entry['label']}\")\n",
    "    print(f\"Text: {entry['clinical_conditions']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(updated_data)\n",
    "dataset = Dataset.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset\n",
    "train_test_split = dataset.train_test_split(test_size=0.8)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pinecone\n",
    "\n",
    "# setting the API key from Pinecone and environment from console\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY') or '27f3cdbb-b72d-4e4b-9351-e221b0e9deae',\n",
    "    environment=os.environ.get('PINECONE_ENVIRONMENT') or 'gcp-starter'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"document sample 1\",\n",
    "    \"document sample 2\"\n",
    "]\n",
    "\n",
    "embeddings = embed_model.embed_documents(docs)\n",
    "\n",
    "print(f\"We have {len(embeddings)} doc embeddings, each with \"\n",
    "      f\"a dimensionality of {len(embeddings[0])}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'thesis-days'\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(embeddings[0]),\n",
    "        metric='cosine'\n",
    "    )\n",
    "    # wait for index to finish initialization\n",
    "    while not pinecone.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pinecone.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pinecone.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = train_dataset.to_pandas()\n",
    "\n",
    "batch_size = 32\n",
    "id_offset = 0\n",
    "\n",
    "for i in range(0, len(dataset), batch_size):\n",
    "    i_end = min(len(dataset), i + batch_size)\n",
    "    batch = dataset.iloc[i:i_end]\n",
    "\n",
    "    # Assuming 'label' and 'clinical_conditions' are the column names\n",
    "    chunk_ids = [str(id_offset + i + 1) for i, _ in enumerate(batch.iterrows())]\n",
    "\n",
    "    label_texts = [x['label'] for _, x in batch.iterrows()]\n",
    "    clinical_conditions_texts = [x['clinical_conditions'] for _, x in batch.iterrows()]\n",
    "\n",
    "    label_embeds = embed_model.embed_documents(label_texts)\n",
    "    clinical_conditions_embeds = embed_model.embed_documents(clinical_conditions_texts)\n",
    "\n",
    "    metadata_chunks = [\n",
    "    {'text': \"The following is a clinical description that corresponds to a specific medical condition. The description: '\" + clinical_conditions + \"' It's diagnosis: '\" + label + \"'.\"} \n",
    "    for label, clinical_conditions in zip(label_texts, clinical_conditions_texts)\n",
    "    ]\n",
    "    # Assuming the Pinecone index is named 'index'\n",
    "    for chunk_id, label_embed, clinical_conditions_embed, metadata_chunk in zip(chunk_ids, label_embeds, clinical_conditions_embeds, metadata_chunks):\n",
    "        adjusted_id = f\"{chunk_id}_{metadata_chunk['text']}\".encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "        # Truncate the adjusted_id to fit within the length limit\n",
    "        adjusted_id = adjusted_id[:512]\n",
    "\n",
    "        index.upsert(vectors=[(adjusted_id, clinical_conditions_embed, metadata_chunk)])\n",
    "\n",
    "    id_offset += len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the first few metadata entries to check\n",
    "for i, metadata in enumerate(metadata_chunks[:9]):\n",
    "    print(f\"Metadata {i}: {metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "\n",
    "#device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#set quantization \n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "hf_auth = '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'\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    #device_map='auto',\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,  # langchain expects the full text\n",
    "    task='text-generation',\n",
    "    # we pass model parameters here too\n",
    "    temperature=0.6,  # 'randomness' of outputs\n",
    "    max_new_tokens=300,  # mex number of tokens to generate in the output\n",
    "    repetition_penalty=1.0  # without this output begins repeating\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = 'text'  # field in metadata that contains text content\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, embed_model.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "rag_pipeline = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type='stuff',\n",
    "    retriever=vectorstore.as_retriever()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the generated responses\n",
    "generated_responses = []\n",
    "\n",
    "# Specify the number of descriptions to generate diagnosis for\n",
    "num_descriptions_to_generate = 50\n",
    "\n",
    "# Iterate over the dataset\n",
    "for index, data in enumerate(test_dataset):\n",
    "    if index >= num_descriptions_to_generate:\n",
    "        break  \n",
    "    description = data['clinical_conditions']\n",
    "    generated_text = (\n",
    "    \"Medical Diagnosis Task: You are presented with a clinical description. \"\n",
    "    \"Based on this description, identify the most appropriate medical category for diagnosis. Respond with one of the following categories, no explanations are needed. \"\n",
    "    \"The categories are: \\n\"\n",
    "    \"1. Neoplasms\\n\"\n",
    "    \"2. Digestive System Diseases\\n\"\n",
    "    \"3. Nervous System Diseases\\n\"\n",
    "    \"4. Cardiovascular Diseases\\n\"\n",
    "    \"5. General Pathological Conditions\\n\\n\"\n",
    "    f\"Clinical Description: '{description}'\\n\"\n",
    "    \"Diagnosis: \"\n",
    ")\n",
    "    \n",
    "    # Use the RAG pipeline with the generated_text\n",
    "    response = rag_pipeline(generated_text)\n",
    "    \n",
    "    # Append the generated response (result) to the list\n",
    "    generated_responses.append(response['result'])  # Extract 'result' from the response dictionary\n",
    "\n",
    "# Now, generated_responses will contain only the results (generated summaries) for the first 5 titles in the dataset\n",
    "\n",
    "actual_summaries = [test_dataset[i]['label'] for i in range(0, 50)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the regular expression pattern\n",
    "pattern = r'(1|2|3|4|5|[A-Za-z\\s]+|[1-5][.: -]\\s*[A-Za-z\\s]+)'\n",
    "\n",
    "# Define the label mapping\n",
    "label_mapping = {\n",
    "    '1': 'neoplasms',\n",
    "    '2': 'digestive system diseases',\n",
    "    '3': 'nervous system diseases',\n",
    "    '4': 'cardiovascular diseases',\n",
    "    '5': 'general pathological conditions',\n",
    "    'neoplasms': 'neoplasms',\n",
    "    'digestive system diseases': 'digestive system diseases',\n",
    "    'nervous system diseases': 'nervous system diseases',\n",
    "    'cardiovascular diseases': 'cardiovascular diseases',\n",
    "    'general pathological conditions': 'general pathological conditions',\n",
    "    '1. neoplasms': 'neoplasms',\n",
    "    '2. digestive system diseases': 'digestive system diseases',\n",
    "    '3. nervous system diseases': 'nervous system diseases',\n",
    "    '4. cardiovascular diseases': 'cardiovascular diseases',\n",
    "    '5. general pathological conditions': 'general pathological conditions',\n",
    "    '1 - neoplasms': 'neoplasms',\n",
    "    '2 - digestive system diseases': 'digestive system diseases',\n",
    "    '3 - nervous system diseases': 'nervous system diseases',\n",
    "    '4 - cardiovascular diseases': 'cardiovascular diseases',\n",
    "    '5 - general pathological conditions': 'general pathological conditions',\n",
    "    '1: neoplasms': 'neoplasms',\n",
    "    '2: digestive system diseases': 'digestive system diseases',\n",
    "    '3: nervous system diseases': 'nervous system diseases',\n",
    "    '4: cardiovascular diseases': 'cardiovascular diseases',\n",
    "    '5: general pathological conditions': 'general pathological conditions',\n",
    "    '1 (Neoplasms)': 'neoplasms',\n",
    "    '2 (Digestive System Diseases)': 'digestive system diseases',\n",
    "    '3 (Nervous System Diseases)': 'nervous system diseases',\n",
    "    '4 (cardiovascular diseases)': 'cardiovascular diseases',\n",
    "    '5 (General Pathological Conditions)': 'general pathological conditions',\n",
    "}\n",
    "\n",
    "# Define label keywords\n",
    "label_keywords = {\n",
    "    'neoplasms': ['neoplasms'],\n",
    "    'digestive system diseases': ['digestive system diseases'],\n",
    "    'nervous system diseases': ['nervous system diseases'],\n",
    "    'cardiovascular diseases': ['cardiovascular diseases'],\n",
    "    'general pathological conditions': ['general pathological conditions'],\n",
    "}\n",
    "\n",
    "# Function to find label based on keywords\n",
    "def find_label_based_on_keywords(text):\n",
    "    for label, keywords in label_keywords.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword.lower() in text.lower():\n",
    "                return label\n",
    "    return None\n",
    "\n",
    "# Extract relevant part from each output and map to actual labels\n",
    "extracted_parts = []\n",
    "\n",
    "for output in generated_responses:\n",
    "    label_found = find_label_based_on_keywords(output)\n",
    "    if label_found:\n",
    "        extracted_parts.append(label_found)\n",
    "    else:\n",
    "        matches = re.findall(pattern, output)\n",
    "        extracted_part = None\n",
    "        for match in matches:\n",
    "            match = match.strip()\n",
    "            if match in label_mapping:\n",
    "                extracted_part = match\n",
    "                break\n",
    "        if extracted_part:\n",
    "            mapped_label = label_mapping[extracted_part]\n",
    "            extracted_parts.append(mapped_label)\n",
    "        else:\n",
    "            extracted_parts.append(\"Unknown\")\n",
    "\n",
    "# Filter out \"Unknown\" responses from actual_labels and extracted_parts\n",
    "filtered_actual_labels = [label for label, predicted in zip(actual_summaries, extracted_parts) if predicted != \"Unknown\"]\n",
    "filtered_extracted_parts = [predicted for predicted in extracted_parts if predicted != \"Unknown\"]\n",
    "\n",
    "# Ensure both lists are of the same length\n",
    "if len(filtered_actual_labels) != len(filtered_extracted_parts):\n",
    "    raise ValueError(\"The number of actual labels and predicted labels must be the same.\")\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(filtered_actual_labels, filtered_extracted_parts)\n",
    "precision = precision_score(filtered_actual_labels, filtered_extracted_parts, average='weighted', labels=np.unique(filtered_extracted_parts))\n",
    "recall = recall_score(filtered_actual_labels, filtered_extracted_parts, average='weighted', labels=np.unique(filtered_extracted_parts))\n",
    "f1 = f1_score(filtered_actual_labels, filtered_extracted_parts, average='weighted', labels=np.unique(filtered_extracted_parts))\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Weighted Precision:\", precision)\n",
    "print(\"Weighted Recall:\", recall)\n",
    "print(\"Weighted F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Labels for the metrics\n",
    "labels = ['Accuracy', 'Weighted Precision', 'Weighted Recall', 'Weighted F1']\n",
    "\n",
    "# Values for the metrics (replace with your actual calculated values)\n",
    "values = [accuracy, precision, recall, f1]\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(\"Metrics:\")\n",
    "for label, value in zip(labels, values):\n",
    "    print(f\"{label}: {value}\")\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(labels, values, color=['blue', 'green', 'orange', 'red'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Evaluation Metrics')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewEnvPy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

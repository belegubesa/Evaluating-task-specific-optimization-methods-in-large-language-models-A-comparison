{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.config.use_cache = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Path to the processed medical text dataset which contains labels in words rather than numbers\n",
    "updated_json_file_path = '/root/llama/datasets/classification_task_new_labels.json'  \n",
    "\n",
    "# Read the updated JSON file\n",
    "with open(updated_json_file_path, 'r', encoding='utf-8') as file:\n",
    "    updated_data = json.load(file)\n",
    "\n",
    "# Let's display five first entries\n",
    "num_entries_to_display = 5\n",
    "\n",
    "# Print those entries to check the labels\n",
    "for entry in updated_data[:num_entries_to_display]:\n",
    "    print(f\"Label: {entry['label']}\")\n",
    "    print(f\"Text: {entry['clinical_conditions']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(updated_data)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "train_testvalid_split = dataset.train_test_split(test_size=0.3)\n",
    "\n",
    "# Splitting the 30% into half for validation and test\n",
    "test_valid_split = train_testvalid_split['test'].train_test_split(test_size=0.5)\n",
    "\n",
    "# Combining splits into a DatasetDict\n",
    "split_datasets = DatasetDict({\n",
    "    'train': train_testvalid_split['train'],\n",
    "    'validation': test_valid_split['train'],\n",
    "    'test': test_valid_split['test']\n",
    "})\n",
    "split_datasets\n",
    "train_dataset = split_datasets['train']\n",
    "validation_dataset = split_datasets['validation']\n",
    "test_dataset = split_datasets['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding another 'text' column\n",
    "def add_text_column(example):\n",
    "    new_text = \"The following is a clinical description that corresponds to a specific medical condition. The description: '\" + example['clinical_conditions'] + \"'. Its diagnosis: '\" + example['label'] + \"'.\"\n",
    "    return {'text': new_text}\n",
    "\n",
    "# Applying the function to each dataset\n",
    "train_dataset = train_dataset.map(add_text_column)\n",
    "validation_dataset = validation_dataset.map(add_text_column)\n",
    "test_dataset = test_dataset.map(add_text_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "peft_parameters = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=8,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = \"./results\"\n",
    "per_device_train_batch_size = 4\n",
    "gradient_accumulation_steps = 4\n",
    "optim = \"paged_adamw_32bit\"\n",
    "save_steps = 100\n",
    "logging_steps = 50\n",
    "learning_rate = 2e-4\n",
    "max_grad_norm = 0.4\n",
    "#max_steps = 100\n",
    "warmup_ratio = 0.03\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    evaluation_strategy=\"steps\", \n",
    "    eval_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    fp16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    #max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "max_seq_length = 400\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=validation_dataset,\n",
    "    peft_config=peft_parameters,\n",
    "    dataset_text_field=\"text\",  \n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in trainer.model.named_modules():\n",
    "    if \"norm\" in name:\n",
    "        module = module.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_wandb = False\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig.from_pretrained('outputs')\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizer, PreTrainedModel\n",
    "\n",
    "# We will initialize an empty list to store the prompts\n",
    "generated_summaries = []\n",
    "prompts = []\n",
    "num_descriptions_to_generate = 50\n",
    "\n",
    "# Iterating over the dataset to create prompts\n",
    "for index, data in enumerate(train_dataset):\n",
    "    if index >= num_descriptions_to_generate:\n",
    "        break\n",
    "    clinical_conditions = data['clinical_conditions']\n",
    "#    prompt = (\n",
    "#        \"Medical Diagnosis Task: You are presented with a clinical description. \"\n",
    "#        \"Based on this description, identify the most appropriate medical category for diagnosis. Respond with one of the following categories, no explanations are needed. \"\n",
    "#        \"The categories are: \\n\"\n",
    "#        \"1. Neoplasms\\n\"\n",
    "#        \"2. Digestive System Diseases\\n\"\n",
    "#        \"3. Nervous System Diseases\\n\"\n",
    "#        \"4. Cardiovascular Diseases\\n\"\n",
    "#        \"5. General Pathological Conditions\\n\\n\"\n",
    "#        f\"Clinical Description: '{clinical_conditions}'\\n\"\n",
    "#        \"Diagnosis: \"\n",
    "#    )\n",
    "    prompt = (\n",
    "    \"User: Can you help me diagnose a medical condition based on a clinical description? Please only state the diagnosis.\\n\"\n",
    "    \"Assistant: Of course. Please provide the clinical description, and I will identify the most appropriate medical category for diagnosis. Respond with one of the following categories, no explanations are needed. The categories are: \\n\"\n",
    "    \"1. Neoplasms\\n\"\n",
    "    \"2. Digestive System Diseases\\n\"\n",
    "    \"3. Nervous System Diseases\\n\"\n",
    "    \"4. Cardiovascular Diseases\\n\"\n",
    "    \"5. General Pathological Conditions\\n\\n\"\n",
    "    f\"User: Here is the clinical description: '{clinical_conditions}'.\\n\"\n",
    "    \"Assistant: The diagnosis is: \"\n",
    ")\n",
    "\n",
    "    prompts.append(prompt)\n",
    "\n",
    "# Here we generate responses using the model\n",
    "for prompt in prompts:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=400)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Removing the prompt part from the generated text\n",
    "    prompt_end_marker = \"Assistant: The diagnosis is: \"\n",
    "    if prompt_end_marker in generated_text:\n",
    "        start_index = generated_text.find(prompt_end_marker) + len(prompt_end_marker)\n",
    "        filtered_text = generated_text[start_index:].strip()\n",
    "    else:\n",
    "        filtered_text = generated_text\n",
    "\n",
    "    generated_summaries.append(filtered_text)\n",
    "\n",
    "actual_labels = [train_dataset[i]['label'] for i in range(num_descriptions_to_generate)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_index = 6  # for testing and viewing the results\n",
    "\n",
    "# Print the data at the chosen index\n",
    "print(\"Prompt at Index {}:\".format(display_index))\n",
    "print(prompts[display_index])\n",
    "print(\"\\nGenerated Response at Index {}:\".format(display_index))\n",
    "print(generated_summaries[display_index])\n",
    "print(\"\\nActual Label at Index {}:\".format(display_index))\n",
    "print(actual_labels[display_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Definiton of the regular expression pattern based on the observed responses\n",
    "pattern = r'(1|2|3|4|5|[A-Za-z\\s]+|[1-5][.: -]\\s*[A-Za-z\\s]+)'\n",
    "\n",
    "# Label mapping defining\n",
    "label_mapping = {\n",
    "    '1': 'neoplasms',\n",
    "    '2': 'digestive system diseases',\n",
    "    '3': 'nervous system diseases',\n",
    "    '4': 'cardiovascular diseases',\n",
    "    '5': 'general pathological conditions',\n",
    "    'neoplasms': 'neoplasms',\n",
    "    'digestive system diseases': 'digestive system diseases',\n",
    "    'nervous system diseases': 'nervous system diseases',\n",
    "    'cardiovascular diseases': 'cardiovascular diseases',\n",
    "    'general pathological conditions': 'general pathological conditions',\n",
    "    '1. neoplasms': 'neoplasms',\n",
    "    '2. digestive system diseases': 'digestive system diseases',\n",
    "    '3. nervous system diseases': 'nervous system diseases',\n",
    "    '4. cardiovascular diseases': 'cardiovascular diseases',\n",
    "    '5. general pathological conditions': 'general pathological conditions',\n",
    "    '1 - neoplasms': 'neoplasms',\n",
    "    '2 - digestive system diseases': 'digestive system diseases',\n",
    "    '3 - nervous system diseases': 'nervous system diseases',\n",
    "    '4 - cardiovascular diseases': 'cardiovascular diseases',\n",
    "    '5 - general pathological conditions': 'general pathological conditions',\n",
    "    '1: neoplasms': 'neoplasms',\n",
    "    '2: digestive system diseases': 'digestive system diseases',\n",
    "    '3: nervous system diseases': 'nervous system diseases',\n",
    "    '4: cardiovascular diseases': 'cardiovascular diseases',\n",
    "    '5: general pathological conditions': 'general pathological conditions',\n",
    "    '1 (Neoplasms)': 'neoplasms',\n",
    "    '2 (Digestive System Diseases)': 'digestive system diseases',\n",
    "    '3 (Nervous System Diseases)': 'nervous system diseases',\n",
    "    '4 (cardiovascular diseases)': 'cardiovascular diseases',\n",
    "    '5 (General Pathological Conditions)': 'general pathological conditions',\n",
    "}\n",
    "\n",
    "# Label keywords defining\n",
    "label_keywords = {\n",
    "    'neoplasms': ['neoplasms'],\n",
    "    'digestive system diseases': ['digestive system diseases'],\n",
    "    'nervous system diseases': ['nervous system diseases'],\n",
    "    'cardiovascular diseases': ['cardiovascular diseases'],\n",
    "    'general pathological conditions': ['general pathological conditions'],\n",
    "}\n",
    "\n",
    "# Function to find label based on keywords\n",
    "def find_label_based_on_keywords(text):\n",
    "    for label, keywords in label_keywords.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword.lower() in text.lower():\n",
    "                return label\n",
    "    return None\n",
    "\n",
    "# Extract relevant part from each output and map to actual labels\n",
    "extracted_parts = []\n",
    "\n",
    "for output in generated_summaries:\n",
    "    label_found = find_label_based_on_keywords(output)\n",
    "    if label_found:\n",
    "        extracted_parts.append(label_found)\n",
    "    else:\n",
    "        matches = re.findall(pattern, output)\n",
    "        extracted_part = None\n",
    "        for match in matches:\n",
    "            match = match.strip()\n",
    "            if match in label_mapping:\n",
    "                extracted_part = match\n",
    "                break\n",
    "        if extracted_part:\n",
    "            mapped_label = label_mapping[extracted_part]\n",
    "            extracted_parts.append(mapped_label)\n",
    "        else:\n",
    "            extracted_parts.append(\"Unknown\")\n",
    "\n",
    "# Filter out \"Unknown\" responses from actual_labels and extracted_parts\n",
    "filtered_actual_labels = [label for label, predicted in zip(actual_labels, extracted_parts) if predicted != \"Unknown\"]\n",
    "filtered_extracted_parts = [predicted for predicted in extracted_parts if predicted != \"Unknown\"]\n",
    "\n",
    "# Ensure both lists are of the same length\n",
    "if len(filtered_actual_labels) != len(filtered_extracted_parts):\n",
    "    raise ValueError(\"The number of actual labels and predicted labels must be the same.\")\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(filtered_actual_labels, filtered_extracted_parts)\n",
    "precision = precision_score(filtered_actual_labels, filtered_extracted_parts, average='weighted', labels=np.unique(filtered_extracted_parts))\n",
    "recall = recall_score(filtered_actual_labels, filtered_extracted_parts, average='weighted', labels=np.unique(filtered_extracted_parts))\n",
    "f1 = f1_score(filtered_actual_labels, filtered_extracted_parts, average='weighted', labels=np.unique(filtered_extracted_parts))\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Weighted Precision:\", precision)\n",
    "print(\"Weighted Recall:\", recall)\n",
    "print(\"Weighted F1 Score:\", f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpeft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

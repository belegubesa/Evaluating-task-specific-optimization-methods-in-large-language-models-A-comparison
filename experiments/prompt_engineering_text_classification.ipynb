{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dat_file_path = 'root/llama/datasets/train.dat'  # Replace with the path to your .dat file\n",
    "json_file_path = 'root/llama/datasets/classification_train.json'  # Replace with your desired path for the .json file\n",
    "\n",
    "# Read the .dat file and process each line\n",
    "data = []\n",
    "with open(dat_file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        if line.strip():  # Check if line is not empty\n",
    "            parts = line.strip().split('\\t')  # Splitting by the tab\n",
    "            if len(parts) >= 2:\n",
    "                label = parts[0]\n",
    "                text = ' '.join(parts[1:])  # Join the remaining parts as text\n",
    "                data.append({'label': label, 'clinical_conditions': text})\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dat_file_path = 'root/llama/datasets/test.dat'  # Replace with the path to your .dat file\n",
    "json_file_path = 'root/llama/datasets/classification_test.json'  # Replace with your desired path for the .json file\n",
    "\n",
    "# Read the .dat file and process each line\n",
    "data = []\n",
    "with open(dat_file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        if line.strip():  # Check if line is not empty\n",
    "            parts = line.strip().split('\\t')  # Splitting by the tab\n",
    "            if len(parts) >= 2:\n",
    "                label = parts[0]\n",
    "                text = ' '.join(parts[1:])  # Join the remaining parts as text\n",
    "                data.append({'label': label, 'clinical_conditions': text})\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(json_file_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Path to your JSON file\n",
    "json_file_path = 'root/llama/datasets/classification_train.json'  # Update with the actual path to your JSON file\n",
    "\n",
    "# Read the JSON file\n",
    "with open(json_file_path, 'r', encoding='utf-8') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Print the type of data and its first element (if available)\n",
    "print(\"Type of JSON data:\", type(data))\n",
    "if isinstance(data, list) and len(data) > 0:\n",
    "    print(\"Type of first element:\", type(data[0]))\n",
    "    print(\"First element:\", data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Defining labels to disease mapping\n",
    "label_to_disease = {\n",
    "    1: \"neoplasms\",\n",
    "    2: \"digestive system diseases\",\n",
    "    3: \"nervous system diseases\",\n",
    "    4: \"cardiovascular diseases\",\n",
    "    5: \"general pathological conditions\"\n",
    "}\n",
    "\n",
    "# Path to your original JSON file and the new file\n",
    "json_file_path = '/root/llama/datasets/classification_train.json'\n",
    "new_json_file_path = '/root/llama/datasets/classification_task_new_labels.json'\n",
    "\n",
    "# Read the original JSON data\n",
    "with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Update the labels\n",
    "for entry in data:\n",
    "    # Convert the label to an integer if it's a string\n",
    "    label = int(entry['label']) if isinstance(entry['label'], str) else entry['label']\n",
    "    # Update the label to its disease name\n",
    "    if label in label_to_disease:\n",
    "        entry['label'] = label_to_disease[label]\n",
    "\n",
    "# Write the updated data to a new JSON file\n",
    "with open(new_json_file_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(data, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Path to your updated JSON file\n",
    "updated_json_file_path = '/root/llama/datasets/classification_task_new_labels.json'  \n",
    "\n",
    "# Read the updated JSON file\n",
    "with open(updated_json_file_path, 'r', encoding='utf-8') as file:\n",
    "    updated_data = json.load(file)\n",
    "\n",
    "# Number of entries to display\n",
    "num_entries_to_display = 5\n",
    "\n",
    "# Print the first few entries to check the labels\n",
    "for entry in updated_data[:num_entries_to_display]:\n",
    "    print(f\"Label: {entry['label']}\")\n",
    "    print(f\"Text: {entry['clinical_conditions']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Path to your updated JSON file\n",
    "updated_json_file_path = '/root/llama/datasets/classification_task_new_labels.json'  \n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('json', data_files=updated_json_file_path)\n",
    "\n",
    "# Check the dataset structure\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "base_model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_name)\n",
    "\n",
    "# Convert model to use 16-bit floating point precision (half precision)\n",
    "model = model.half()  # This converts all the model weights to float16\n",
    "\n",
    "# Tokenizer\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_tokenizer.padding_side = \"right\"  # Fix for fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    f\"Medical Diagnosis Task: You are presented with a clinical description. Based on this description, identify the most appropriate medical category for diagnosis. The categories are: \\n 1. Neoplasms\\n 2. Digestive System Diseases\\n 3. Nervous System Diseases\\n 4. Cardiovascular Diseases\\n 5. General Pathological Conditions\\n\\nClinical Description: '{dataset['train'][i]['clinical_conditions']}'\\nDiagnosis: \"\n",
    "    for i in range(20)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Print the device being used\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Check if the model is wrapped in DataParallel and unwrap it if necessary\n",
    "if isinstance(model, torch.nn.DataParallel):\n",
    "    # Extract the original model from DataParallel wrapper\n",
    "    unwrapped_model = model.module\n",
    "else:\n",
    "    unwrapped_model = model\n",
    "\n",
    "# Move the unwrapped model to the defined device (GPU or CPU)\n",
    "unwrapped_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = []\n",
    "for prompt in prompts:\n",
    "    input_ids = llama_tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    output_ids = unwrapped_model.generate(input_ids, max_length=512, temperature=0.4, top_p=0.6)\n",
    "    generated_text = llama_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Post-processing to remove the echoed prompt\n",
    "    if generated_text.startswith(prompt):\n",
    "        generated_text = generated_text[len(prompt):].strip()\n",
    "\n",
    "    # Append the generated text directly\n",
    "    model_outputs.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract generated plus actual summaries\n",
    "generated_summaries = model_outputs\n",
    "actual_labels = [dataset['train'][i]['label'] for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Define the regular expression pattern to capture the relevant part\n",
    "pattern = r'(1|2|3|4|5|[A-Za-z\\s]+|[1-5][.: -]\\s*[A-Za-z\\s]+)'\n",
    "\n",
    "# Define the label mapping\n",
    "label_mapping = {\n",
    "    '1': 'neoplasms',\n",
    "    '2': 'digestive system diseases',\n",
    "    '3': 'nervous system diseases',\n",
    "    '4': 'cardiovascular diseases',\n",
    "    '5': 'general pathological conditions',\n",
    "    'neoplasms': 'neoplasms',\n",
    "    'digestive system diseases': 'digestive system diseases',\n",
    "    'nervous system diseases': 'nervous system diseases',\n",
    "    'cardiovascular diseases': 'cardiovascular diseases',\n",
    "    'general pathological conditions': 'general pathological conditions',\n",
    "    '1. neoplasms': 'neoplasms',\n",
    "    '2. digestive system diseases': 'digestive system diseases',\n",
    "    '3. nervous system diseases': 'nervous system diseases',\n",
    "    '4. cardiovascular diseases': 'cardiovascular diseases',\n",
    "    '5. general pathological conditions': 'general pathological conditions',\n",
    "    '1 - neoplasms': 'neoplasms',\n",
    "    '2 - digestive system diseases': 'digestive system diseases',\n",
    "    '3 - nervous system diseases': 'nervous system diseases',\n",
    "    '4 - cardiovascular diseases': 'cardiovascular diseases',\n",
    "    '5 - general pathological conditions': 'general pathological conditions',\n",
    "    '1: neoplasms': 'neoplasms',\n",
    "    '2: digestive system diseases': 'digestive system diseases',\n",
    "    '3: nervous system diseases': 'nervous system diseases',\n",
    "    '4: cardiovascular diseases': 'cardiovascular diseases',\n",
    "    '5: general pathological conditions': 'general pathological conditions',\n",
    "}\n",
    "\n",
    "\n",
    "# Extract the relevant part from each generated output and map it to actual labels\n",
    "extracted_parts = []\n",
    "\n",
    "for output in generated_summaries:\n",
    "    matches = re.findall(pattern, output)\n",
    "    extracted_part = None\n",
    "    \n",
    "    for match in matches:\n",
    "        match = match.strip()\n",
    "        if match in label_mapping:\n",
    "            extracted_part = match\n",
    "            break\n",
    "    \n",
    "    if extracted_part and extracted_part != \"Unknown\":\n",
    "        mapped_label = label_mapping[extracted_part]\n",
    "        extracted_parts.append(mapped_label)\n",
    "\n",
    "# Filter out \"Unknown\" responses from the actual_labels\n",
    "filtered_actual_labels = [label for label in actual_labels if label != \"Unknown\"]\n",
    "\n",
    "# Calculate fuzzy matching scores and check if they exceed the threshold\n",
    "threshold = 80  # You can adjust the threshold as needed\n",
    "correct_predictions = [fuzz.ratio(actual, extracted) >= threshold for actual, extracted in zip(filtered_actual_labels, extracted_parts)]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = sum(correct_predictions) / len(correct_predictions)\n",
    "\n",
    "# Initialize counters for precision, recall, and F1 calculation\n",
    "true_positives = Counter()\n",
    "false_positives = Counter()\n",
    "false_negatives = Counter()\n",
    "\n",
    "for i, correct in enumerate(correct_predictions):\n",
    "    if correct:\n",
    "        true_positives[filtered_actual_labels[i]] += 1\n",
    "    else:\n",
    "        false_positives[extracted_parts[i]] += 1\n",
    "        false_negatives[filtered_actual_labels[i]] += 1\n",
    "\n",
    "# Calculate precision, recall, and F1 for each label\n",
    "precision = {label: true_positives[label] / (true_positives[label] + false_positives[label]) if (true_positives[label] + false_positives[label]) != 0 else 0 for label in set(filtered_actual_labels)}\n",
    "recall = {label: true_positives[label] / (true_positives[label] + false_negatives[label]) if (true_positives[label] + false_negatives[label]) != 0 else 0 for label in set(filtered_actual_labels)}\n",
    "f1 = {label: 2 * (precision[label] * recall[label]) / (precision[label] + recall[label]) if (precision[label] + recall[label]) != 0 else 0 for label in set(filtered_actual_labels)}\n",
    "\n",
    "# Calculate weighted averages\n",
    "weighted_precision = np.average(list(precision.values()), weights=[true_positives[label] + false_positives[label] for label in set(filtered_actual_labels)])\n",
    "weighted_recall = np.average(list(recall.values()), weights=[true_positives[label] + false_negatives[label] for label in set(filtered_actual_labels)])\n",
    "weighted_f1 = np.average(list(f1.values()), weights=[true_positives[label] + false_positives[label] for label in set(filtered_actual_labels)])\n",
    "\n",
    "# Print or use the calculated metrics as needed\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Weighted Precision:\", weighted_precision)\n",
    "print(\"Weighted Recall:\", weighted_recall)\n",
    "print(\"Weighted F1:\", weighted_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the label mapping\n",
    "label_mapping = {\n",
    "    '1': 'neoplasms',\n",
    "    '2': 'digestive system diseases',\n",
    "    '3': 'nervous system diseases',\n",
    "    '4': 'cardiovascular diseases',\n",
    "    '5': 'general pathological conditions',\n",
    "    'neoplasms': 'neoplasms',\n",
    "    'digestive system diseases': 'digestive system diseases',\n",
    "    'nervous system diseases': 'nervous system diseases',\n",
    "    'cardiovascular diseases': 'cardiovascular diseases',\n",
    "    'general pathological conditions': 'general pathological conditions',\n",
    "    '1. neoplasms': 'neoplasms',\n",
    "    '2. digestive system diseases': 'digestive system diseases',\n",
    "    '3. nervous system diseases': 'nervous system diseases',\n",
    "    '4. cardiovascular diseases': 'cardiovascular diseases',\n",
    "    '5. general pathological conditions': 'general pathological conditions',\n",
    "    '1 - neoplasms': 'neoplasms',\n",
    "    '2 - digestive system diseases': 'digestive system diseases',\n",
    "    '3 - nervous system diseases': 'nervous system diseases',\n",
    "    '4 - cardiovascular diseases': 'cardiovascular diseases',\n",
    "    '5 - general pathological conditions': 'general pathological conditions',\n",
    "    '1: neoplasms': 'neoplasms',\n",
    "    '2: digestive system diseases': 'digestive system diseases',\n",
    "    '3: nervous system diseases': 'nervous system diseases',\n",
    "    '4: cardiovascular diseases': 'cardiovascular diseases',\n",
    "    '5: general pathological conditions': 'general pathological conditions',\n",
    "}\n",
    "\n",
    "# Extract the relevant part from each generated output and map it to actual labels\n",
    "mapped_labels = []\n",
    "\n",
    "for output in generated_summaries:\n",
    "    matches = re.findall(r'(1|2|3|4|5|[A-Za-z\\s]+|[1-5][.: -]\\s*[A-Za-z\\s]+)', output)\n",
    "    mapped_label = None\n",
    "\n",
    "    for match in matches:\n",
    "        match = match.strip()\n",
    "        if match in label_mapping:\n",
    "            mapped_label = label_mapping[match]\n",
    "            break\n",
    "\n",
    "    if mapped_label:\n",
    "        mapped_labels.append(mapped_label)\n",
    "    else:\n",
    "        mapped_labels.append(\"Unknown\")\n",
    "\n",
    "# Filter out \"Unknown\" responses from the actual_labels\n",
    "filtered_actual_labels = [label for label in actual_labels if label != \"Unknown\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(filtered_actual_labels, mapped_labels)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(filtered_actual_labels, mapped_labels, average='weighted')\n",
    "recall = recall_score(filtered_actual_labels, mapped_labels, average='weighted')\n",
    "f1 = f1_score(filtered_actual_labels, mapped_labels, average='weighted')\n",
    "\n",
    "# Print or use the calculated metrics as needed\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Weighted Precision:\", precision)\n",
    "print(\"Weighted Recall:\", recall)\n",
    "print(\"Weighted F1:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Labels for the metrics\n",
    "labels = ['Accuracy', 'Weighted Precision', 'Weighted Recall', 'Weighted F1']\n",
    "\n",
    "# Values for the metrics (replace with your actual calculated values)\n",
    "values = [accuracy, precision, recall, f1]\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(\"Metrics:\")\n",
    "for label, value in zip(labels, values):\n",
    "    print(f\"{label}: {value}\")\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(labels, values, color=['blue', 'green', 'orange', 'red'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Evaluation Metrics')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the 25th entry\n",
    "index = 17  # 25th entry has index 24\n",
    "\n",
    "print(f\"Prompt:\\n{prompts[index]}\\n\")\n",
    "print(f\"Generated Label:\\n{generated_summaries[index]}\\n\")\n",
    "print(f\"Actual Label:\\n{actual_labels[index]}\\n\")\n",
    "print(\"---------------------------------------------------\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpeft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
